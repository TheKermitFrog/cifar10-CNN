{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Path Variables\n",
    "bucket='sagemaker-cifar10-2020'\n",
    "folder = 'cifar-10-batches-py'\n",
    "\n",
    "##################################\n",
    "# Data Related Variables\n",
    "num_file_train = 5\n",
    "num_images_per_file = 10000\n",
    "num_images_train = 50000\n",
    "num_images_test = 10000\n",
    "num_image_dim = 3072\n",
    "##################################\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_class_names():\n",
    "    key = 'batches.meta'\n",
    "    data_location = './cifar-10-batches-py/{}'.format(key)\n",
    "    class_names = unpickle(data_location).get(b'label_names')\n",
    "    names = [x.decode('utf-8') for x in class_names]\n",
    "    return names\n",
    "\n",
    "# Read training data in from S3\n",
    "def load_training():\n",
    "    images = np.zeros(shape=[num_images_train, num_image_dim], dtype=float)\n",
    "    cls = np.zeros(shape=[num_images_train], dtype=int)\n",
    "    \n",
    "    ind = 0\n",
    "    \n",
    "    for i in range(1, num_file_train + 1):\n",
    "        data_key = 'data_batch_' + str(i)\n",
    "        data_location = './cifar-10-batches-py/{}'.format(data_key)\n",
    "        data = unpickle(data_location)\n",
    "        num_images = data.get(b'data').shape[0]\n",
    "        start = ind\n",
    "        end = ind + num_images\n",
    "        images[start:end, :] = data.get(b'data') / 255.0 # conver to 0-1 representation\n",
    "        cls[start:end] = data.get(b'labels')\n",
    "        \n",
    "        ind += num_images\n",
    "        \n",
    "    return images, cls\n",
    "\n",
    "# Read testing data in from S3\n",
    "def load_testing():\n",
    "    data_key = 'test_batch'\n",
    "    data_location = './cifar-10-batches-py/{}'.format(data_key)\n",
    "    data = unpickle(data_location)\n",
    "    images = data.get(b'data') / 255.0 # conver to 0-1 representation\n",
    "    cls = np.array(data.get(b'labels'))\n",
    "    \n",
    "    return images, cls\n",
    "\n",
    "# General purpose image plotting\n",
    "def plot_image(image):\n",
    "    image_reshape = image.reshape(3, 32, 32).transpose(1,2,0)\n",
    "    plt.imshow(image_reshape)\n",
    "\n",
    "# Plot 5 random chosen images\n",
    "def plot_random_images(images):\n",
    "    num = 5\n",
    "    fig, axes1 = plt.subplots(num, num, figsize=(8, 8))\n",
    "    for j in range(num):\n",
    "        for k in range(num):\n",
    "            i = np.random.choice(range(images.shape[0]))\n",
    "            image = images[i]\n",
    "            image_reshape = image.reshape(3, 32, 32).transpose(1,2,0)\n",
    "            axes1[j][k].set_axis_off()\n",
    "            axes1[j][k].imshow(image_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_class = load_training()\n",
    "test_images, test_class = load_testing()\n",
    "\n",
    "# pd.DataFrame(train_images).to_csv('train_images.csv', index=False, header=False)\n",
    "# pd.DataFrame(train_class).to_csv('train_class.csv', index=False, header=False)\n",
    "\n",
    "# pd.DataFrame(test_images).to_csv('test_images.csv', index=False, header=False)\n",
    "# pd.DataFrame(test_class).to_csv('test_class.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, X_train, _, y_train = train_test_split(train_images, train_class, test_size=0.1, random_state=42, stratify=train_class)\n",
    "del _, train_images, train_class, test_images, test_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenwang/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/darrenwang/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "clf_xgb = xgb.XGBClassifier(learning_rate =0.1,\n",
    "                     n_estimators=1000,\n",
    "                     min_child_weight=1,\n",
    "                     gamma=0,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     objective='multi:softmax',\n",
    "                     num_class=10,\n",
    "                     seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X = pca.fit_transform(X_train)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y_train)\n",
    "\n",
    "        \n",
    "xgtrain = xgb.DMatrix(X.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    # Other parameters\n",
    "    'objective':'multi:softmax',\n",
    "    'num_class': 10,\n",
    "    'nthread': -1,\n",
    "    'seed' : 42,\n",
    "    'eval_metric': ['merror', 'auc']\n",
    "}\n",
    "\n",
    "evallist = [(xgtrain, 'train')]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [3, 5, 7, 10]\n",
    "# Minimum number of samples required to split a node\n",
    "min_child_weight = [1, 3, 5]\n",
    "\n",
    "num_boost_round = 1000\n",
    "\n",
    "model = xgb.cv(\n",
    "    params,\n",
    "    xgtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    nfold=2,\n",
    "    seed=42,\n",
    "    metrics={'merror'},\n",
    "    early_stopping_rounds=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,4)\n",
    "    for min_child_weight in range(1,2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=3, min_child_weight=1\n",
      "\tMERROR 0.6674000000000001 for 19 rounds\n",
      "Best params: 3, 1, MERROR: 0.6674000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darrenwang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: \n",
      "The current behaviour of 'Series.argmin' is deprecated, use 'idxmin'\n",
      "instead.\n",
      "The behavior of 'argmin' will be corrected to return the positional\n",
      "minimum in the future. For now, use 'series.values.argmin' or\n",
      "'np.argmin(np.array(values))' to get the position of the minimum\n",
      "row.\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xgtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].values.argmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ea9ea3049a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "cv_results.predict(xgtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
